{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Import Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shap\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, learning_curve\n",
    "from sklearn.metrics import roc_curve, auc, mean_squared_error\n",
    "from sklearn import metrics\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "os.chdir(r'D:\\Projects\\MachineLearning\\textrnn')\n",
    "plt.switch_backend('agg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Some Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_roc(labels, predict_prob, save_prefix=''):\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(labels, predict_prob)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    plt.clf()\n",
    "    plt.title('ROC')\n",
    "    plt.plot(false_positive_rate, true_positive_rate, 'b', label='AUC = %0.4f' % roc_auc)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot([0, 1], [0, 1], 'r--')\n",
    "    plt.ylabel('TPR')\n",
    "    plt.xlabel('FPR')\n",
    "    if save_prefix:\n",
    "        plt.savefig(f'{save_prefix}_roc.jpg')\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "def plot_learning_curve(algo, X_train, X_test, y_train, y_test, save_prefix=''):\n",
    "    \"\"\"绘制学习曲线：只需要传入算法(或实例对象)、X_train、X_test、y_train、y_test\"\"\"\n",
    "    \"\"\"当使用该函数时传入算法，该算法的变量要进行实例化，如：PolynomialRegression(degree=2)，变量 degree 要进行实例化\"\"\"\n",
    "    train_score = []\n",
    "    test_score = []\n",
    "    for i in range(1, len(X_train) + 1):\n",
    "        algo.fit(X_train[:i], y_train[:i])\n",
    "\n",
    "        y_train_predict = algo.predict(X_train[:i])\n",
    "        train_score.append(mean_squared_error(y_train[:i], y_train_predict))\n",
    "\n",
    "        y_test_predict = algo.predict(X_test)\n",
    "        test_score.append(mean_squared_error(y_test, y_test_predict))\n",
    "\n",
    "    plt.clf()\n",
    "    plt.plot([i for i in range(1, len(X_train) + 1)],\n",
    "             np.sqrt(train_score), label=\"train\")\n",
    "    plt.plot([i for i in range(1, len(X_train) + 1)],\n",
    "             np.sqrt(test_score), label=\"test\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.axis([0, len(X_train) + 1, 0, 4])\n",
    "    if save_prefix:\n",
    "        plt.savefig(f'{save_prefix}_learning_curve.jpg')\n",
    "\n",
    "\n",
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid, valid_label, save_prefix=''):\n",
    "    plot_learning_curve(classifier, feature_vector_train, feature_vector_valid, label, valid_label, save_prefix)\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "\n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "\n",
    "    # ROC curve\n",
    "    plot_roc(valid_label, predictions, save_prefix)\n",
    "    #\n",
    "    # # Feature importance\n",
    "    plt.clf()\n",
    "    fig, ax = plt.subplots(figsize=(15, 15))\n",
    "    plot_importance(classifier,\n",
    "                    height=0.5,\n",
    "                    ax=ax,\n",
    "                    max_num_features=64)\n",
    "    # plt.show()\n",
    "    if save_prefix:\n",
    "        plt.savefig(f'{save_prefix}_feature_importance.jpg')\n",
    "\n",
    "    return classifier, metrics.accuracy_score(predictions, valid_label), metrics.classification_report(predictions,\n",
    "                                                                                                       valid_label)\n",
    "\n",
    "\n",
    "def clock(time_start):\n",
    "    time_end = time.time()\n",
    "    return time_end - time_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Some Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_load_time = []\n",
    "ngram_time = []\n",
    "smote_time = []\n",
    "train_with_all_feature_time = []\n",
    "shap_pre_train_time = []\n",
    "shap_time = []\n",
    "shap_train_time = []\n",
    "\n",
    "acc_all = []\n",
    "acc_part = []\n",
    "acc_shap = []\n",
    "\n",
    "file = pd.read_csv('data.csv')\n",
    "df = pd.DataFrame(file)\n",
    "_header = ['underflow', 'overflow', 'callstack', 'tod', 'timestamp', 'reentrancy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-02 17:48:23.052 | INFO     | __main__:<module>:2 - start: underflow\n",
      "2022-06-02 17:48:23.082 | INFO     | __main__:<module>:13 - load data: 0.02263188362121582s\n",
      "2022-06-02 17:49:04.321 | INFO     | __main__:<module>:21 - ngram: 41.23729968070984s\n",
      "2022-06-02 17:50:54.149 | INFO     | __main__:<module>:29 - smote: 109.8266761302948s\n",
      "2022-06-02 17:50:54.623 | INFO     | __main__:<module>:33 - After OverSampling, counts of label '1': 22030\n",
      "2022-06-02 17:50:54.708 | INFO     | __main__:<module>:34 - After OverSampling, counts of label '0': 22030\n",
      "2022-06-02 17:50:54.709 | INFO     | __main__:<module>:37 - ***************Train with all data****************\n",
      "2022-06-02 17:52:15.496 | INFO     | __main__:<module>:45 - Xgb, Accuracy: 0.9268421848993796\n",
      "2022-06-02 17:52:15.497 | INFO     | __main__:<module>:49 - train with all data: 80.37347888946533s\n",
      "2022-06-02 17:52:15.498 | INFO     | __main__:<module>:51 - **************************************************\n",
      "2022-06-02 17:52:15.498 | INFO     | __main__:<module>:55 - **************PreTrain with 10% data**************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      6665\n",
      "           1       0.93      0.93      0.93      6553\n",
      "\n",
      "    accuracy                           0.93     13218\n",
      "   macro avg       0.93      0.93      0.93     13218\n",
      "weighted avg       0.93      0.93      0.93     13218\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-02 17:52:20.901 | INFO     | __main__:<module>:64 - Xgb, Accuracy: 0.8963691376701967\n",
      "2022-06-02 17:52:20.902 | INFO     | __main__:<module>:68 - train with 10% of data: 4.767791032791138s\n",
      "2022-06-02 17:52:20.902 | INFO     | __main__:<module>:70 - **************************************************\n",
      "2022-06-02 17:52:20.903 | INFO     | __main__:<module>:74 - *******************SHAP Explain*******************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90       676\n",
      "           1       0.89      0.91      0.90       646\n",
      "\n",
      "    accuracy                           0.90      1322\n",
      "   macro avg       0.90      0.90      0.90      1322\n",
      "weighted avg       0.90      0.90      0.90      1322\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-02 17:52:21.640 | INFO     | __main__:<module>:79 - ngram: 0.7372868061065674s\n",
      "2022-06-02 17:52:21.641 | INFO     | __main__:<module>:81 - **************************************************\n",
      "2022-06-02 17:52:21.654 | INFO     | __main__:<module>:87 - ****************Feature selection*****************\n",
      "2022-06-02 17:52:22.217 | INFO     | __main__:<module>:90 - useful features: 332\n",
      "2022-06-02 17:52:22.218 | INFO     | __main__:<module>:91 - all features: 3249\n",
      "2022-06-02 17:52:22.218 | INFO     | __main__:<module>:92 - **************************************************\n",
      "2022-06-02 17:52:22.218 | INFO     | __main__:<module>:96 - *******************Final Train********************\n",
      "2022-06-02 17:52:35.203 | INFO     | __main__:<module>:104 - Xgb, Accuracy: 0.9355424421243759\n",
      "2022-06-02 17:52:35.204 | INFO     | __main__:<module>:108 - train after shap: 12.945550203323364s\n",
      "2022-06-02 17:52:35.204 | INFO     | __main__:<module>:110 - **************************************************\n",
      "2022-06-02 17:52:35.205 | INFO     | __main__:<module>:2 - start: overflow\n",
      "2022-06-02 17:52:35.250 | INFO     | __main__:<module>:13 - load data: 0.03789877891540527s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94      2233\n",
      "           1       0.93      0.94      0.93      2173\n",
      "\n",
      "    accuracy                           0.94      4406\n",
      "   macro avg       0.94      0.94      0.94      4406\n",
      "weighted avg       0.94      0.94      0.94      4406\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-02 17:53:16.674 | INFO     | __main__:<module>:21 - ngram: 41.42358756065369s\n",
      "2022-06-02 17:53:54.775 | INFO     | __main__:<module>:29 - smote: 38.09956169128418s\n",
      "2022-06-02 17:53:55.357 | INFO     | __main__:<module>:33 - After OverSampling, counts of label '1': 28682\n",
      "2022-06-02 17:53:55.467 | INFO     | __main__:<module>:34 - After OverSampling, counts of label '0': 28682\n",
      "2022-06-02 17:53:55.467 | INFO     | __main__:<module>:37 - ***************Train with all data****************\n",
      "2022-06-02 17:55:44.741 | INFO     | __main__:<module>:45 - Xgb, Accuracy: 0.9268448576409064\n",
      "2022-06-02 17:55:44.742 | INFO     | __main__:<module>:49 - train with all data: 108.78346395492554s\n",
      "2022-06-02 17:55:44.743 | INFO     | __main__:<module>:51 - **************************************************\n",
      "2022-06-02 17:55:44.743 | INFO     | __main__:<module>:55 - **************PreTrain with 10% data**************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93      8461\n",
      "           1       0.94      0.91      0.93      8749\n",
      "\n",
      "    accuracy                           0.93     17210\n",
      "   macro avg       0.93      0.93      0.93     17210\n",
      "weighted avg       0.93      0.93      0.93     17210\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-02 17:55:52.738 | INFO     | __main__:<module>:64 - Xgb, Accuracy: 0.859465737514518\n",
      "2022-06-02 17:55:52.738 | INFO     | __main__:<module>:68 - train with 10% of data: 7.052079916000366s\n",
      "2022-06-02 17:55:52.739 | INFO     | __main__:<module>:70 - **************************************************\n",
      "2022-06-02 17:55:52.739 | INFO     | __main__:<module>:74 - *******************SHAP Explain*******************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86       848\n",
      "           1       0.88      0.84      0.86       874\n",
      "\n",
      "    accuracy                           0.86      1722\n",
      "   macro avg       0.86      0.86      0.86      1722\n",
      "weighted avg       0.86      0.86      0.86      1722\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-02 17:55:53.784 | INFO     | __main__:<module>:79 - ngram: 1.0432264804840088s\n",
      "2022-06-02 17:55:53.784 | INFO     | __main__:<module>:81 - **************************************************\n",
      "2022-06-02 17:55:53.798 | INFO     | __main__:<module>:87 - ****************Feature selection*****************\n",
      "2022-06-02 17:55:54.495 | INFO     | __main__:<module>:90 - useful features: 375\n",
      "2022-06-02 17:55:54.496 | INFO     | __main__:<module>:91 - all features: 3249\n",
      "2022-06-02 17:55:54.496 | INFO     | __main__:<module>:92 - **************************************************\n",
      "2022-06-02 17:55:54.497 | INFO     | __main__:<module>:96 - *******************Final Train********************\n",
      "2022-06-02 17:56:15.319 | INFO     | __main__:<module>:104 - Xgb, Accuracy: 0.9351577479518912\n",
      "2022-06-02 17:56:15.320 | INFO     | __main__:<module>:108 - train after shap: 20.74999499320984s\n",
      "2022-06-02 17:56:15.321 | INFO     | __main__:<module>:110 - **************************************************\n",
      "2022-06-02 17:56:15.321 | INFO     | __main__:<module>:2 - start: callstack\n",
      "2022-06-02 17:56:15.367 | INFO     | __main__:<module>:13 - load data: 0.03757882118225098s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93      2814\n",
      "           1       0.95      0.92      0.94      2923\n",
      "\n",
      "    accuracy                           0.94      5737\n",
      "   macro avg       0.94      0.94      0.94      5737\n",
      "weighted avg       0.94      0.94      0.94      5737\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-02 17:56:57.386 | INFO     | __main__:<module>:21 - ngram: 42.018487215042114s\n",
      "2022-06-02 17:56:58.271 | INFO     | __main__:<module>:29 - smote: 0.8839643001556396s\n",
      "2022-06-02 17:56:59.066 | INFO     | __main__:<module>:33 - After OverSampling, counts of label '1': 43123\n",
      "2022-06-02 17:56:59.232 | INFO     | __main__:<module>:34 - After OverSampling, counts of label '0': 43123\n",
      "2022-06-02 17:56:59.232 | INFO     | __main__:<module>:37 - ***************Train with all data****************\n",
      "2022-06-02 17:59:47.713 | INFO     | __main__:<module>:45 - Xgb, Accuracy: 0.9971399860864189\n",
      "2022-06-02 17:59:47.719 | INFO     | __main__:<module>:49 - train with all data: 167.81923651695251s\n",
      "2022-06-02 17:59:47.720 | INFO     | __main__:<module>:51 - **************************************************\n",
      "2022-06-02 17:59:47.720 | INFO     | __main__:<module>:55 - **************PreTrain with 10% data**************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12720\n",
      "           1       1.00      1.00      1.00     13154\n",
      "\n",
      "    accuracy                           1.00     25874\n",
      "   macro avg       1.00      1.00      1.00     25874\n",
      "weighted avg       1.00      1.00      1.00     25874\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-02 17:59:58.635 | INFO     | __main__:<module>:64 - Xgb, Accuracy: 0.9783616692426584\n",
      "2022-06-02 17:59:58.637 | INFO     | __main__:<module>:68 - train with 10% of data: 9.147855997085571s\n",
      "2022-06-02 17:59:58.637 | INFO     | __main__:<module>:70 - **************************************************\n",
      "2022-06-02 17:59:58.638 | INFO     | __main__:<module>:74 - *******************SHAP Explain*******************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      1258\n",
      "           1       0.99      0.96      0.98      1330\n",
      "\n",
      "    accuracy                           0.98      2588\n",
      "   macro avg       0.98      0.98      0.98      2588\n",
      "weighted avg       0.98      0.98      0.98      2588\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-02 17:59:59.946 | INFO     | __main__:<module>:79 - ngram: 1.3080761432647705s\n",
      "2022-06-02 17:59:59.947 | INFO     | __main__:<module>:81 - **************************************************\n",
      "2022-06-02 17:59:59.955 | INFO     | __main__:<module>:87 - ****************Feature selection*****************\n",
      "2022-06-02 18:00:00.831 | INFO     | __main__:<module>:90 - useful features: 370\n",
      "2022-06-02 18:00:00.832 | INFO     | __main__:<module>:91 - all features: 3249\n",
      "2022-06-02 18:00:00.833 | INFO     | __main__:<module>:92 - **************************************************\n",
      "2022-06-02 18:00:00.833 | INFO     | __main__:<module>:96 - *******************Final Train********************\n",
      "2022-06-02 18:00:29.863 | INFO     | __main__:<module>:104 - Xgb, Accuracy: 0.9977971014492754\n",
      "2022-06-02 18:00:29.864 | INFO     | __main__:<module>:108 - train after shap: 28.918010473251343s\n",
      "2022-06-02 18:00:29.865 | INFO     | __main__:<module>:110 - **************************************************\n",
      "2022-06-02 18:00:29.865 | INFO     | __main__:<module>:2 - start: tod\n",
      "2022-06-02 18:00:29.936 | INFO     | __main__:<module>:13 - load data: 0.06781840324401855s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4277\n",
      "           1       1.00      1.00      1.00      4348\n",
      "\n",
      "    accuracy                           1.00      8625\n",
      "   macro avg       1.00      1.00      1.00      8625\n",
      "weighted avg       1.00      1.00      1.00      8625\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-02 18:01:11.690 | INFO     | __main__:<module>:21 - ngram: 41.75332427024841s\n",
      "2022-06-02 18:01:15.143 | INFO     | __main__:<module>:29 - smote: 3.4534034729003906s\n",
      "2022-06-02 18:01:15.921 | INFO     | __main__:<module>:33 - After OverSampling, counts of label '1': 39958\n",
      "2022-06-02 18:01:16.091 | INFO     | __main__:<module>:34 - After OverSampling, counts of label '0': 39958\n",
      "2022-06-02 18:01:16.092 | INFO     | __main__:<module>:37 - ***************Train with all data****************\n",
      "2022-06-02 18:03:51.999 | INFO     | __main__:<module>:45 - Xgb, Accuracy: 0.9790615224191866\n",
      "2022-06-02 18:03:52.000 | INFO     | __main__:<module>:49 - train with all data: 155.1601264476776s\n",
      "2022-06-02 18:03:52.001 | INFO     | __main__:<module>:51 - **************************************************\n",
      "2022-06-02 18:03:52.001 | INFO     | __main__:<module>:55 - **************PreTrain with 10% data**************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     11610\n",
      "           1       0.99      0.97      0.98     12365\n",
      "\n",
      "    accuracy                           0.98     23975\n",
      "   macro avg       0.98      0.98      0.98     23975\n",
      "weighted avg       0.98      0.98      0.98     23975\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-02 18:04:01.442 | INFO     | __main__:<module>:64 - Xgb, Accuracy: 0.932443703085905\n",
      "2022-06-02 18:04:01.443 | INFO     | __main__:<module>:68 - train with 10% of data: 8.227896928787231s\n",
      "2022-06-02 18:04:01.443 | INFO     | __main__:<module>:70 - **************************************************\n",
      "2022-06-02 18:04:01.444 | INFO     | __main__:<module>:74 - *******************SHAP Explain*******************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.93      1082\n",
      "           1       0.96      0.91      0.94      1316\n",
      "\n",
      "    accuracy                           0.93      2398\n",
      "   macro avg       0.93      0.93      0.93      2398\n",
      "weighted avg       0.93      0.93      0.93      2398\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-02 18:04:02.810 | INFO     | __main__:<module>:79 - ngram: 1.3667628765106201s\n",
      "2022-06-02 18:04:02.810 | INFO     | __main__:<module>:81 - **************************************************\n",
      "2022-06-02 18:04:02.838 | INFO     | __main__:<module>:87 - ****************Feature selection*****************\n",
      "2022-06-02 18:04:03.606 | INFO     | __main__:<module>:90 - useful features: 384\n",
      "2022-06-02 18:04:03.606 | INFO     | __main__:<module>:91 - all features: 3249\n",
      "2022-06-02 18:04:03.607 | INFO     | __main__:<module>:92 - **************************************************\n",
      "2022-06-02 18:04:03.608 | INFO     | __main__:<module>:96 - *******************Final Train********************\n",
      "2022-06-02 18:04:33.126 | INFO     | __main__:<module>:104 - Xgb, Accuracy: 0.9834834834834835\n",
      "2022-06-02 18:04:33.127 | INFO     | __main__:<module>:108 - train after shap: 29.420985460281372s\n",
      "2022-06-02 18:04:33.127 | INFO     | __main__:<module>:110 - **************************************************\n",
      "2022-06-02 18:04:33.128 | INFO     | __main__:<module>:2 - start: timestamp\n",
      "2022-06-02 18:04:33.191 | INFO     | __main__:<module>:13 - load data: 0.0549163818359375s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      3860\n",
      "           1       0.99      0.98      0.98      4132\n",
      "\n",
      "    accuracy                           0.98      7992\n",
      "   macro avg       0.98      0.98      0.98      7992\n",
      "weighted avg       0.98      0.98      0.98      7992\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-02 18:05:13.669 | INFO     | __main__:<module>:21 - ngram: 40.477155685424805s\n",
      "2022-06-02 18:05:14.556 | INFO     | __main__:<module>:29 - smote: 0.886854887008667s\n",
      "2022-06-02 18:05:15.371 | INFO     | __main__:<module>:33 - After OverSampling, counts of label '1': 42602\n",
      "2022-06-02 18:05:15.528 | INFO     | __main__:<module>:34 - After OverSampling, counts of label '0': 42602\n",
      "2022-06-02 18:05:15.528 | INFO     | __main__:<module>:37 - ***************Train with all data****************\n",
      "2022-06-02 18:07:49.169 | INFO     | __main__:<module>:45 - Xgb, Accuracy: 0.9938189500039121\n",
      "2022-06-02 18:07:49.170 | INFO     | __main__:<module>:49 - train with all data: 152.99942302703857s\n",
      "2022-06-02 18:07:49.170 | INFO     | __main__:<module>:51 - **************************************************\n",
      "2022-06-02 18:07:49.171 | INFO     | __main__:<module>:55 - **************PreTrain with 10% data**************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     12607\n",
      "           1       1.00      0.99      0.99     12955\n",
      "\n",
      "    accuracy                           0.99     25562\n",
      "   macro avg       0.99      0.99      0.99     25562\n",
      "weighted avg       0.99      0.99      0.99     25562\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-02 18:07:58.877 | INFO     | __main__:<module>:64 - Xgb, Accuracy: 0.9655846695346109\n",
      "2022-06-02 18:07:58.878 | INFO     | __main__:<module>:68 - train with 10% of data: 8.535696983337402s\n",
      "2022-06-02 18:07:58.879 | INFO     | __main__:<module>:70 - **************************************************\n",
      "2022-06-02 18:07:58.879 | INFO     | __main__:<module>:74 - *******************SHAP Explain*******************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      1225\n",
      "           1       0.98      0.96      0.97      1332\n",
      "\n",
      "    accuracy                           0.97      2557\n",
      "   macro avg       0.97      0.97      0.97      2557\n",
      "weighted avg       0.97      0.97      0.97      2557\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-02 18:08:00.185 | INFO     | __main__:<module>:79 - ngram: 1.3052122592926025s\n",
      "2022-06-02 18:08:00.186 | INFO     | __main__:<module>:81 - **************************************************\n",
      "2022-06-02 18:08:00.212 | INFO     | __main__:<module>:87 - ****************Feature selection*****************\n",
      "2022-06-02 18:08:00.983 | INFO     | __main__:<module>:90 - useful features: 363\n",
      "2022-06-02 18:08:00.984 | INFO     | __main__:<module>:91 - all features: 3249\n",
      "2022-06-02 18:08:00.985 | INFO     | __main__:<module>:92 - **************************************************\n",
      "2022-06-02 18:08:00.985 | INFO     | __main__:<module>:96 - *******************Final Train********************\n",
      "2022-06-02 18:08:26.817 | INFO     | __main__:<module>:104 - Xgb, Accuracy: 0.9951883581739233\n",
      "2022-06-02 18:08:26.818 | INFO     | __main__:<module>:108 - train after shap: 25.739964246749878s\n",
      "2022-06-02 18:08:26.818 | INFO     | __main__:<module>:110 - **************************************************\n",
      "2022-06-02 18:08:26.818 | INFO     | __main__:<module>:2 - start: reentrancy\n",
      "2022-06-02 18:08:26.863 | INFO     | __main__:<module>:13 - load data: 0.037899017333984375s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      4203\n",
      "           1       1.00      0.99      1.00      4318\n",
      "\n",
      "    accuracy                           1.00      8521\n",
      "   macro avg       1.00      1.00      1.00      8521\n",
      "weighted avg       1.00      1.00      1.00      8521\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-02 18:09:07.040 | INFO     | __main__:<module>:21 - ngram: 40.17670679092407s\n",
      "2022-06-02 18:09:07.695 | INFO     | __main__:<module>:29 - smote: 0.6544938087463379s\n",
      "2022-06-02 18:09:08.481 | INFO     | __main__:<module>:33 - After OverSampling, counts of label '1': 43654\n",
      "2022-06-02 18:09:08.644 | INFO     | __main__:<module>:34 - After OverSampling, counts of label '0': 43654\n",
      "2022-06-02 18:09:08.644 | INFO     | __main__:<module>:37 - ***************Train with all data****************\n",
      "2022-06-02 18:11:40.054 | INFO     | __main__:<module>:45 - Xgb, Accuracy: 0.9988164776848777\n",
      "2022-06-02 18:11:40.062 | INFO     | __main__:<module>:49 - train with all data: 150.6295599937439s\n",
      "2022-06-02 18:11:40.063 | INFO     | __main__:<module>:51 - **************************************************\n",
      "2022-06-02 18:11:40.063 | INFO     | __main__:<module>:55 - **************PreTrain with 10% data**************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12922\n",
      "           1       1.00      1.00      1.00     13271\n",
      "\n",
      "    accuracy                           1.00     26193\n",
      "   macro avg       1.00      1.00      1.00     26193\n",
      "weighted avg       1.00      1.00      1.00     26193\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-02 18:11:49.939 | INFO     | __main__:<module>:64 - Xgb, Accuracy: 0.9923664122137404\n",
      "2022-06-02 18:11:49.940 | INFO     | __main__:<module>:68 - train with 10% of data: 8.622464895248413s\n",
      "2022-06-02 18:11:49.941 | INFO     | __main__:<module>:70 - **************************************************\n",
      "2022-06-02 18:11:49.941 | INFO     | __main__:<module>:74 - *******************SHAP Explain*******************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1284\n",
      "           1       1.00      0.99      0.99      1336\n",
      "\n",
      "    accuracy                           0.99      2620\n",
      "   macro avg       0.99      0.99      0.99      2620\n",
      "weighted avg       0.99      0.99      0.99      2620\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-02 18:11:51.073 | INFO     | __main__:<module>:79 - ngram: 1.1311311721801758s\n",
      "2022-06-02 18:11:51.074 | INFO     | __main__:<module>:81 - **************************************************\n",
      "2022-06-02 18:11:51.105 | INFO     | __main__:<module>:87 - ****************Feature selection*****************\n",
      "2022-06-02 18:11:51.899 | INFO     | __main__:<module>:90 - useful features: 337\n",
      "2022-06-02 18:11:51.899 | INFO     | __main__:<module>:91 - all features: 3249\n",
      "2022-06-02 18:11:51.900 | INFO     | __main__:<module>:92 - **************************************************\n",
      "2022-06-02 18:11:51.900 | INFO     | __main__:<module>:96 - *******************Final Train********************\n",
      "2022-06-02 18:12:14.815 | INFO     | __main__:<module>:104 - Xgb, Accuracy: 0.9988546558240752\n",
      "2022-06-02 18:12:14.816 | INFO     | __main__:<module>:108 - train after shap: 22.81123971939087s\n",
      "2022-06-02 18:12:14.816 | INFO     | __main__:<module>:110 - **************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4291\n",
      "           1       1.00      1.00      1.00      4440\n",
      "\n",
      "    accuracy                           1.00      8731\n",
      "   macro avg       1.00      1.00      1.00      8731\n",
      "weighted avg       1.00      1.00      1.00      8731\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in _header:\n",
    "    logger.info(f'start: {i}')\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    # 数据加载\n",
    "    time_start = time.time()\n",
    "    for x, y in zip(df.iloc[:, df.columns == 'opcode']['opcode'], df.iloc[:, df.columns == i][i]):\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    Y = np.array(Y)\n",
    "    time_used = clock(time_start)\n",
    "    logger.info(f'load data: {time_used}s')\n",
    "    data_load_time.append(time_used)\n",
    "\n",
    "    # Ngram\n",
    "    time_start = time.time()\n",
    "    ngram_vectorizer = CountVectorizer(ngram_range=(2, 2), decode_error=\"ignore\", min_df=1)\n",
    "    X = ngram_vectorizer.fit_transform(X)\n",
    "    time_used = clock(time_start)\n",
    "    logger.info(f'ngram: {time_used}s')\n",
    "    ngram_time.append(time_used)\n",
    "\n",
    "    # Smote\n",
    "    time_start = time.time()\n",
    "    sm = SMOTE(random_state=2)\n",
    "    X_train_res, y_train_res = sm.fit_resample(X, Y.ravel())\n",
    "    time_used = clock(time_start)\n",
    "    logger.info(f'smote: {time_used}s')\n",
    "    smote_time.append(time_used)\n",
    "\n",
    "    all_df = pd.DataFrame(X_train_res.todense(), columns=ngram_vectorizer.get_feature_names_out())\n",
    "    logger.info(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res == 1)))\n",
    "    logger.info(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res == 0)))\n",
    "\n",
    "    # 使用源数据集训练\n",
    "    logger.info(\"{:*^50}\".format(\"Train with all data\"))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(all_df, y_train_res, test_size=0.3, random_state=0)\n",
    "    model = XGBClassifier(learning_rate=0.2, max_depth=12, verbosity=0)\n",
    "    time_start = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    accuracy = metrics.accuracy_score(predictions, y_test)\n",
    "    confusion_matrix = metrics.classification_report(predictions, y_test)\n",
    "    logger.info(f\"Xgb, Accuracy: {accuracy}\")\n",
    "    acc_all.append(accuracy)\n",
    "    print(confusion_matrix)\n",
    "    time_used = clock(time_start)\n",
    "    logger.info(f'train with all data: {time_used}s')\n",
    "    train_with_all_feature_time.append(time_used)\n",
    "    logger.info(\"{:*^50}\".format(\"\"))\n",
    "\n",
    "    # 使用十分之一的数据集先进行训练\n",
    "    # for j in [10]:\n",
    "    logger.info(\"{:*^50}\".format(\"PreTrain with 10% data\"))\n",
    "    _, test_df_x, _, test_df_y = train_test_split(all_df, y_train_res, test_size=0.1, random_state=0)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(test_df_x, test_df_y, test_size=0.3, random_state=0)\n",
    "    model = XGBClassifier()\n",
    "    time_start = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    accuracy = metrics.accuracy_score(predictions, y_test)\n",
    "    confusion_matrix = metrics.classification_report(predictions, y_test)\n",
    "    logger.info(f\"Xgb, Accuracy: {accuracy}\")\n",
    "    acc_part.append(accuracy)\n",
    "    print(confusion_matrix)\n",
    "    time_used = clock(time_start)\n",
    "    logger.info(f'train with {10}% of data: {time_used}s')\n",
    "    shap_pre_train_time.append(time_used)\n",
    "    logger.info(\"{:*^50}\".format(\"\"))\n",
    "    # break\n",
    "\n",
    "    # Shap解释\n",
    "    logger.info(\"{:*^50}\".format(\"SHAP Explain\"))\n",
    "    time_start = time.time()\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values_train = explainer.shap_values(X_train)\n",
    "    time_used = clock(time_start)\n",
    "    logger.info(f'ngram: {time_used}s')\n",
    "    shap_time.append(time_used)\n",
    "    logger.info(\"{:*^50}\".format(\"\"))\n",
    "\n",
    "    txt_dense_df = pd.DataFrame(X_train.loc[::], columns=ngram_vectorizer.get_feature_names_out())\n",
    "    shap_values_train_df = pd.DataFrame(shap_values_train, columns=txt_dense_df.columns)\n",
    "\n",
    "    # 特征筛选\n",
    "    logger.info(\"{:*^50}\".format(\"Feature selection\"))\n",
    "    tmp = shap_values_train_df.apply(np.sum, axis=0) != 0\n",
    "    new_df = all_df.reindex(columns=list(filter(lambda x: tmp[x], tmp.keys())))\n",
    "    logger.info(f'useful features: {len(new_df.columns)}')\n",
    "    logger.info(f'all features: {len(all_df.columns)}')\n",
    "    logger.info(\"{:*^50}\".format(\"\"))\n",
    "    # continue\n",
    "    # break\n",
    "    # 新数据集训练\n",
    "    logger.info(\"{:*^50}\".format(\"Final Train\"))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(new_df, y_train_res, test_size=0.1, random_state=0)\n",
    "    model = XGBClassifier(learning_rate=0.2, max_depth=12)\n",
    "    time_start = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    accuracy = metrics.accuracy_score(predictions, y_test)\n",
    "    confusion_matrix = metrics.classification_report(predictions, y_test)\n",
    "    logger.info(f\"Xgb, Accuracy: {accuracy}\")\n",
    "    acc_shap.append(accuracy)\n",
    "    print(confusion_matrix)\n",
    "    time_used = clock(time_start)\n",
    "    logger.info(f'train after shap: {time_used}s')\n",
    "    shap_train_time.append(time_used)\n",
    "    logger.info(\"{:*^50}\".format(\"\"))\n",
    "\n",
    "    # 绘制曲线\n",
    "    # plot_learning_curve(model, X_train, X_test, y_train, y_test, save_prefix=f'pic/{i}')\n",
    "    # # ROC curve\n",
    "    # plot_roc(y_test, predictions,  save_prefix=f'pic/{i}')\n",
    "    # #\n",
    "    # # # Feature importance\n",
    "    # logger.info('--------start plot feature importance')\n",
    "    # plt.clf()\n",
    "    # fig, ax = plt.subplots(figsize=(15, 15))\n",
    "    # plot_importance(model,\n",
    "    #                 height=0.5,\n",
    "    #                 ax=ax,\n",
    "    #                 max_num_features=64)\n",
    "    # plt.savefig(f'pic/{i}_feature_importance.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-02 20:30:40.799 | INFO     | __main__:<module>:1 - data_load_time = [0.02263188362121582, 0.03789877891540527, 0.03757882118225098, 0.06781840324401855, 0.0549163818359375, 0.037899017333984375]\n",
      "2022-06-02 20:30:40.801 | INFO     | __main__:<module>:2 - ngram_time = [41.23729968070984, 41.42358756065369, 42.018487215042114, 41.75332427024841, 40.477155685424805, 40.17670679092407]\n",
      "2022-06-02 20:30:40.802 | INFO     | __main__:<module>:3 - smote_time = [109.8266761302948, 38.09956169128418, 0.8839643001556396, 3.4534034729003906, 0.886854887008667, 0.6544938087463379]\n",
      "2022-06-02 20:30:40.802 | INFO     | __main__:<module>:4 - train_with_all_feature_time = [80.37347888946533, 108.78346395492554, 167.81923651695251, 155.1601264476776, 152.99942302703857, 150.6295599937439]\n",
      "2022-06-02 20:30:40.803 | INFO     | __main__:<module>:5 - shap_pre_train_time = [4.767791032791138, 7.052079916000366, 9.147855997085571, 8.227896928787231, 8.535696983337402, 8.622464895248413]\n",
      "2022-06-02 20:30:40.803 | INFO     | __main__:<module>:6 - shap_time = [0.7372868061065674, 1.0432264804840088, 1.3080761432647705, 1.3667628765106201, 1.3052122592926025, 1.1311311721801758]\n",
      "2022-06-02 20:30:40.804 | INFO     | __main__:<module>:7 - shap_train_time = [12.945550203323364, 20.74999499320984, 28.918010473251343, 29.420985460281372, 25.739964246749878, 22.81123971939087]\n",
      "2022-06-02 20:30:40.804 | INFO     | __main__:<module>:8 - acc_all = [0.9268421848993796, 0.9268448576409064, 0.9971399860864189, 0.9790615224191866, 0.9938189500039121, 0.9988164776848777]\n",
      "2022-06-02 20:30:40.805 | INFO     | __main__:<module>:9 - acc_part = [0.8963691376701967, 0.859465737514518, 0.9783616692426584, 0.932443703085905, 0.9655846695346109, 0.9923664122137404]\n",
      "2022-06-02 20:30:40.806 | INFO     | __main__:<module>:10 - acc_shap = [0.9355424421243759, 0.9351577479518912, 0.9977971014492754, 0.9834834834834835, 0.9951883581739233, 0.9988546558240752]\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'data_load_time = {data_load_time}')\n",
    "logger.info(f'ngram_time = {ngram_time}')\n",
    "logger.info(f'smote_time = {smote_time}')\n",
    "logger.info(f'train_with_all_feature_time = {train_with_all_feature_time}')\n",
    "logger.info(f'shap_pre_train_time = {shap_pre_train_time}')\n",
    "logger.info(f'shap_time = {shap_time}')\n",
    "logger.info(f'shap_train_time = {shap_train_time}')\n",
    "logger.info(f'acc_all = {acc_all}')\n",
    "logger.info(f'acc_part = {acc_part}')\n",
    "logger.info(f'acc_shap = {acc_shap}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
